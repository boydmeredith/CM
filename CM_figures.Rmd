---
title: "CM mvpa analysis"
output: 
  html_document:
    toc: true

---
This document will contain the figures we publish in our countermeasures manuscript.

#Load packages
First off, we'll need to **load the packages** we plan to use. This is not so different from setting the matlab path at the beginning of a script. 
```{r load_packages}
require(plyr) #plyr is used to summarize data along dimensions we care about
library(ggplot2) #ggplot! our favorite plotting tool
require(gridExtra) #gridExtra let's us arrangement figures into grids
```

#Setup plotting variables
Then, we'll **setup some plotting environment variables** that we'll use to control how our plots look.

```{r set up plot variables}
#the color blind compatible palette we'll use for our colors
cbPalette <- c( "#56B4E9","#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7","#999999", "#E69F00")

#a dashed horizontal line to represent chance for binary classifiers
fiftyline=stat_abline(intercept=.5,slope=0,linetype="dashed",color='black',size=1)

#specify font size and face for axis labels and title
plotformat=theme(title= element_text(face="bold",size=15),axis.title = element_text(face="bold",size=14),axis.text=element_text(size=13))
```

We'll have to be a little bit clever about getting our color palette into the plots, but the 50% chanceline and plotformats we can just do by adding them to our ggplots, i.e. `myplot + fiftyline`. so simple!

If I wasn't using this document as an R markdown tutorial, I would probably not show this code chunk in the html output. I could have hidden it by adding `echo=FALSE` to the code chunk header (note: code chunk headers are the thing in the Rmd that looks like :
```{r <chunk_title>, echo=TRUE, fig.width = 5}```

#Load the data
Now that we've got that setup, we'll **grab the data** that we plan to use a bunch from our 'results_sheets' directory.

```{r load_data}
dir = "~/cm/Scripts/results_sheets" #all our results csvs live here 
#specify the name of each results sheet we'll use
behav_dat_file = sprintf("%s/cm_behav_to_r.csv",dir)
univ_dat_file = sprintf("%s/CM_betas_toR.csv",dir)
mvpa_dat_file = sprintf("%s/aucSummaryToR__exex_excm_cmcm_hitvcr.csv",dir)
#load each results sheet as it's own dataframe
behav_df = read.csv(behav_dat_file, header=T)
univ_df = read.csv(univ_dat_file, header=T)
mvpa_df = read.csv(mvpa_dat_file, header=T)
```

#Behavioral Findings
##Inspect Behavioral Data
The first thing we'll want to do is have a look at the structure of the behavioral data. We'll use `head` and `summary` to do this.

```{r summarize behavior}
head(behav_df) #head shows column headers and the first 6 rows of a data frame
summary(behav_df) #summary provides some information about the distribution of data in the data frame
```

Great. We can see that this data frame contains overall and task-specific d' and Pr for 16 EA subjects and 8 AA subjects

For now, we'll move onto the univariate data. It'll be happy to see us later.

##Inspect univariate data
```{r summarize univariate}
summary(univ_df)
```

Looks like we have a collection of parameter estimates ($\beta$s) for hits and crs in two tasks (ex and cm) from different contrasts and rois of different shapes (cluster vs sphere).  

##Create summary univariate data frame for plotting
A good (but not always necessary) first step to plotting, is to create a summary data frame, with the info you'd like. We'll do that for the mean and sem of the parameter estimates and we'll call the result `univ_dfS`.

```{r create univariate summary dataframe}
univ_dfS = ddply(univ_df,.(Contrast, shape, roi, task, acc),summarise,N=length(beta), mean_beta = mean(beta), sd_beta = sd(beta), sem_beta = sd_beta/sqrt(N), min_beta = mean_beta-sem_beta, max_beta = mean_beta+sem_beta)
summary(univ_dfS)
```

The summary looks great! So, now we can plot make some plots using these mean and sem values.

##Make univariate summary plot
Let's plot our mean $\beta$ for each task and subject accuracy (hit or cr) in facets for each contrast, roi, and sphere vs cluster

First, in order for the plot to display the factors in the order we want, we should reorder them in the data frame.

```{r reorder univ df factors}
univ_dfS$task = factor(univ_dfS$task, levels=c("ex","cm"))
univ_dfS$acc = factor(univ_dfS$acc, levels=c("hit","cr"))
```

Ok, now we can write a quick function to plot the data.


```{r plot univariate data}
plotUnivBetas <- function(pl_df){
#setup a plot h showing mean betas by task and memory
h<-ggplot(pl_df, aes(x=interaction(acc,task), y=mean_beta,ymin=min_beta,ymax=max_beta, fill = task))+#tells our plot what value to put on the x-axis and y-axis and to group values by task. If we tried to plot now, it would say "no layers in plot" and show nothing
   geom_bar(stat='identity',color='black')+
  geom_errorbar(position=position_dodge(1), width=0, size=.7, color='black')+#here's the meat of the plot. this specifies that we want points with error bars, tells it what values to use for the error bars, how big their should be, and that they should be 'dodged' by grouping on the x-axis
  facet_wrap(~roi+Contrast+shape,scales='free_y')+#We'll 'facet' by the remaining factors, thereby making a separate plot for each combo of the factors. Note that we have to specify that y axis can be different in each facet. Now, we've got something we can actually think about plotting. 
  plotformat+  #this just tells our plot that it should have axis labels of a certain size, etc (see "Setup plotting variables" section)
  scale_fill_manual(values=cbPalette,name="Task",breaks=c("ex","cm"),labels=c("Explicit","Countermeasures"))+
  labs(x="memory",y="parameter estimate")+#here we specify what the labels should be
    theme_bw()+
scale_x_discrete(breaks=c("hit.ex","cr.ex","hit.cm","cr.cm"),labels=c("hit","cr","hit","cr"))

return(h)
}
```

Let's look at a first pass with all of the univariate data
```{r first pass univ plot, fig.width=10, fig.height=6}
plotUnivBetas(univ_dfS)+  theme(legend.position=c(.85,0.2)) #let's we move the legend into a postion that's currently vacant
```

##Fig 2. Task x Memory Interaction 
Here is the same plot, using the subset of the data that we present in the manuscript
```{r ms univ plot, fig.width=10, fig.height=3}
univ_dfS_ms = subset(univ_dfS, shape=='sphere' & roi %in% c("Left Ang","Right IPS","Left Hipp"))
plotUnivBetas(univ_dfS_ms)
```

##Fig 3. L Ang parameter estimates correlates with CM d'
We also want to know something about how the angular effects correlate with CM d'. Let's have a look at that.
```{r correlation cm d prime and ang fx sphere}
#first let's grab that cluster
univ_df_ang_sphere = subset(univ_df, shape=='sphere' & roi=="Left Ang" & task=='cm')
#and look at it's structure
summary(univ_df_ang_sphere)
ang_sphere_cm_memsuccess = univ_df_ang_sphere$beta[univ_df_ang_sphere$acc=='hit']-univ_df_ang_sphere$beta[univ_df_ang_sphere$acc=='cr']
cor.test(ang_sphere_cm_memsuccess,behav_df$cm_d)
qplot(behav_df$cm_d,ang_sphere_cm_memsuccess,geom='smooth',method='lm')+geom_point(size=3, fill='white',shape=21)+theme_bw()+labs(x="d' in CM task",y="Retrieval success effects in CM task")+plotformat+geom_abline(intercept=0,slope=0,linetype='dotted')+geom_vline(x=0,linetype='dotted')+annotate('text',x=1.75,y=.25,label='r = .14, p = 0.26')

```

###This correlation is NOT significant at $p<.05$, when we use the *sphere* that produced the data above (for the bar graph). However, it is significant when we use the *cluster* and a one-tailed test.

```{r correlation cm d prime and ang fx cluster}
#first let's grab that cluster
univ_df_ang_clus = subset(univ_df, shape=='cluster' & roi=="Left Ang" & task=='cm')
#and look at it's structure
summary(univ_df_ang_clus)
ang_clus_cm_memsuccess = univ_df_ang_clus$beta[univ_df_ang_clus$acc=='hit']-univ_df_ang_clus$beta[univ_df_ang_clus$acc=='cr']
cor.test(ang_clus_cm_memsuccess,behav_df$cm_d)
qplot(behav_df$cm_d,ang_clus_cm_memsuccess,geom='smooth',method='lm')+geom_point(size=3, fill='white',shape=21)+theme_bw()+labs(x="d' in CM task",y="Retrieval success effects in CM task")+plotformat+geom_abline(intercept=0,slope=0,linetype='dotted')+geom_vline(x=0,linetype='dotted')+annotate('text',x=1.75,y=.25,label='r = .36, p = 0.04')
````


---------------
#MVPA Findings
##Inspect mvpa data frame
```{r summarize mvpa}
summary(mvpa_df)
```

Looks good. It'll be helpful to have a summary of this, so let's go ahead and make another dataframe (`mvpa_dfS`) that summarizes the information with mean, sem, and other info.

```{r make late trs df}
#reorder factors as appropriate
train_test_levels = c('EX,4fold','CM,4fold','EX>CM','CM>EX')
latetrs_mvpa_df = subset(mvpa_df,tr=='late' & train_test %in% train_test_levels)
latetrs_mvpa_df$train_test=factor(latetrs_mvpa_df$train_test,levels=train_test_levels)
#create summary df
mvpa_dfS<-ddply(mvpa_df,c("mask","conds","tr","name","train_test"),summarise,N=length(auc),mean_auc=mean(auc),sd_auc = sd(auc), sem_auc=sd_auc/sqrt(N), min_auc = mean_auc-sem_auc, max_auc = mean_auc+sem_auc)
```

The first thing we'll want to plot, is the ex>ex and ex>cm violins and tr by tr stuff that go into figure 4.

First thing I'll do is write some functions that make these plots easy to create.
####Plotting function for mvpa violins
```{r  mvpa comparison violins}
plotMvpaViolin <- function(pl_df){
  h<-ggplot(pl_df, aes(x=train_test, y=auc))+
    geom_violin(aes(fill=train_test),trim=F,alpha=.6)+
    geom_point(aes(color=sub),show_guide=F)+
    geom_line(aes(color=sub, group=sub),show_guide=F,linetype='dotted')+
    theme_bw()+
    fiftyline+
    theme(axis.ticks=element_blank(),axis.text.x=element_blank())+
    plotformat+
    geom_point(stat='summary',fun.y='mean')
  return(h)
}
```

####Plotting function for mvpa at each tr
```{r  mvpa tr by tr plot}
plotMvpaTrRibbons <- function(pl_df){
  h<-ggplot(pl_df, aes(x=trSec,y=mean_auc,ymin=min_auc,ymax=max_auc, group=train_test, fill=train_test, color=train_test)) +
     geom_ribbon(alpha=.65) + 
    geom_line(linetype="longdash")+
    fiftyline+geom_vline(xintercept=0, linetype="dotted")+
    theme_bw() +
    plotformat
  return(h)
}
```

##Fig 4A. EX>EX & EX>CM Violins

```{r plot train_ex violins }
plotMvpaViolin(subset(latetrs_mvpa_df,train_test %in% c('EX,4fold','EX>CM')))+
  labs(y="Classifier Performance (AUC)", x="Testing Data (task)", title="Classifier Trained on EX")+
  scale_fill_manual(values=cbPalette,name="Testing Data",breaks=c("EX,4fold","EX>CM"),labels=c("EX (cross-validated)","CM"))
```

##Fig 4B. EX>EX & EX>CM TR by TR
First, I want to create a variable `trSec` that corresponds to the number of second post stimulus onset (rather than the tr number), so that we can put that on the x axis

```{r get seconds for tr by tr}
mvpa_dfS$trSec = as.numeric(mvpa_dfS$tr)*2-1
mvpa_dfS$trSec[mvpa_dfS$tr=='late'] = NA
```

Now that I have that, plot away
```{r plot tr by tr training on ex}
plotMvpaTrRibbons(subset(mvpa_dfS, train_test %in% c("EX>CM","EX,4fold")))+
  scale_fill_manual(values=cbPalette,name="Testing Data",breaks=c("EX,4fold","EX>CM"),labels=c("EX (cross-validated)","CM"))+
  scale_color_manual(values=cbPalette,name="Testing Data",breaks=c("EX,4fold","EX>CM"),labels=c("EX (cross-validated)","CM"))+
  labs(x="Time Post Stimulus Onset (s)", y="Classifier Performance (AUC)")
```

##Fig 5A. Classifier Performance by Confidence 
To explore these effects, we're going to need to load new data that looks at trail by trial information, instead of binning across each classifier
###Load data
```{r load_this_mvpa_dat}
mvpa_extocm_tr3_file = sprintf("%s/xvals2_runsrepotred_conds_hitVcr_trTe1_1_1_1_2_2_2_2_trW0__0__1__0__0__0_roiSEPT09_MVPA_MASK_resliced4mm.csv",dir) 

mvpa_extocm_late_file = sprintf("%s/xvals2_runsrepotred_conds_hitVcr_trTe1_1_1_1_2_2_2_2_trWtr0___________0________0.33________0.34________0.33___________0_te0___________0________0.33________0.34________0.33___________0_roiSEPT09_MVPA_MASK_resliced4mm.csv",dir) 


mvpa_ex_late_file = sprintf("%s/xvals_runsrepotred_conds_hitVcr_trTe1_2_3_4_0_0_0_0_trW0___________0________0.33________0.34________0.33___________0_roiSEPT09_MVPA_MASK_resliced4mm.csv",dir) 

mvpa_extocm_tr3_df = read.csv(mvpa_extocm_tr3_file, header=T)
mvpa_extocm_late_df = read.csv(mvpa_extocm_late_file, header=T)
mvpa_ex_late_df = read.csv(mvpa_ex_late_file, header=T)
```

###Add labels to data and combine
```{r add labels and combine}

mvpa_extocm_tr3_df$name = 'extocm_tr3'
mvpa_extocm_late_df$name = 'extocm_late'
mvpa_ex_late_df$name = 'extoex_late'

confbyacc_df = rbind(mvpa_extocm_tr3_df,mvpa_extocm_late_df,mvpa_ex_late_df)
```

###Create percentile confidence bins of the data
```{r build confidence bins, cache = T}
confbyacc_sorted_df = confbyacc_df[with(confbyacc_df, order(name, subs, -abs(actsVec-.5))),]
acc = numeric(0)
subj_num = integer(0)
mvpa_name = character(0)
bin_name = character(0)
bin_num=numeric(0)
  
bins =seq(1,.05,-.05)

names = unique(confbyacc_sorted_df$name)
x=0
for (iname in 1:length(names)){
  this_name = names[iname]
  for (jsub in unique(confbyacc_sorted_df$subs)){
    ntrials = length(with(confbyacc_sorted_df, confbyacc_sorted_df[subs==jsub & name==this_name, "subs"]))
    for (acc_bin in seq(1,20)){
      x=x+1
      included_trial_inds = 1:ceiling(ntrials * bins[acc_bin])
      mvpa_name[x]=this_name
      subj_num[x]=jsub
      bin_name[x] = sprintf('top %s%%',bins[acc_bin]*100)
      bin_num[x]=acc_bin
      acc[x] = with(subset(confbyacc_sorted_df,name==this_name & subs==jsub),mean(correctsVec[included_trial_inds]))
    }
  }
}

mvpa_accbyconf_df = data.frame(sub = subj_num,name = mvpa_name, acc=acc, bin_name=bin_name, bin_num=bin_num)

mvpa_accbyconf_df$bin_name = factor(mvpa_accbyconf_df$bin_name,
                                      levels=(mvpa_accbyconf_df$bin_name[1:20]))

```


###Fit a model and make a plot of accuracy by percentile confidence
```{r plot accuracy by confidence percentile}

confacc_ag<-ddply(mvpa_accbyconf_df,c("bin_num","name"),summarise,N=length(acc),mean_acc=mean(acc),sd_acc = sd(acc), sem_acc=sd_acc/sqrt(N), min_acc = mean_acc-sem_acc, max_acc = mean_acc+sem_acc)

model<- lm(acc~bin_num*name,data=mvpa_accbyconf_df)
grid <- with(mvpa_accbyconf_df, expand.grid(
  name = levels(name),
  bin_num = bin_num
))
grid$acc<-stats::predict(model,newdata=grid)

confacc_plt<-ggplot(mvpa_accbyconf_df,aes(x=bin_num,y=acc,group=name,color=name))+theme_bw()+theme(axis.text.x  = element_text(angle=45, vjust=0.5, size=16))+plotformat+labs(x='percentile confidence bin',y=expression("p(classifier correct)"),title="Classifier accuracy by confidence")

confacc_plt+geom_pointrange(data=confacc_ag,aes(x=bin_num,y=mean_acc,ymin=min_acc,ymax=max_acc),size=.85)+  geom_line(data=grid,size=.75) + scale_x_continuous(labels=mvpa_accbyconf_df$bin_name[seq(1,20,2)],breaks=seq(1,20,2))+scale_color_discrete(breaks=c("extocm_late","extocm_tr3","extoex_late"),labels=c("EX>CM, late TRs", "EX>CM, 3rd TR","EX, 4fold, late TRs"),name='Classifier')
```


##Fig 5B. EX>CM TR3 Classifier Performance by CM d'
```{r cm d prime vs ex to cm tr 3}
excmtr3 = mvpa_df[mvpa_df$tr==3 & mvpa_df$train_test=="EX>CM",]
excmtr3$cm_d = behav_df$cm_d
excmtr3$ex_d = behav_df$ex_d
```

```{r ex d prime not correlated to cm tr 3 auc}
#what about with ex d'?
with(excmtr3,cor.test(auc,ex_d))
```

**EX d' is NOT significantly correlated with EX>CM AUC at tr 3 (4-6s post stimulus)**

```{r cm d prime is correlated to cm tr 3 auc}
#are these correlated with cm d'
with(excmtr3,cor.test(auc,cm_d))
```

**CM d' is significantly correlated with EX>CM AUC at tr 3 (4-6s post stimulus)** 

```{r plot correlation between auc and cm d}
#plot them
ggplot(excmtr3,aes(y=auc,x=cm_d))+geom_smooth(method="lm")+geom_point(size=3,fill='white',shape=21)+theme_bw()+plotformat+labs(y="EX>CM Classifier Performance (AUC)",x="CM Memory Performance (d')")
```


##Fig 6. CM>CM and CM>EX Violins!

```{r plot train_cm violins}
plotMvpaViolin(subset(latetrs_mvpa_df,train_test %in% c('CM,4fold','CM>EX')))+
  labs(y="Classifier Performance (AUC)", x="Testing Data (task)", title="Classifier Trained on CM")+
  scale_fill_manual(values=cbPalette[c(2,1)],name="Testing Data",breaks=c("CM,4fold","CM>EX"),labels=c("CM (cross-validated)","EX"))
```


##Fig ?. Tr Sweep!
First, load the data from our special TR sweep results sheet.
```{r load tr sweep df}
trsweepexcm_file = sprintf('%s/aucSummary__EXCMTrSweep.csv',dir)
trsweepexcm_df = read.csv(trsweepexcm_file,header=T)
trsweep_df=trsweepexcm_df
```

Then, get the mean, and sem of auc in this data grouped by trained and testing trs, and whether or not the data is scrambled.

```{r summarize_tr_swweep_df}
trsweep_dfS<-ddply(trsweep_df,c("tr_train","tr_test","tr_te","scrambled"),summarise,N=length(auc),mean_auc=mean(auc),sd_auc = sd(auc), sem_auc=sd_auc/sqrt(N))
```

Now, we'll check for significance. Whether our results are significant should depend on our choice of `m` (where we want $p \le \alpha/m)

```{r tr_sweep_significance}
#train tr 3, test tr 3 above chance
with(subset(trsweep_df, tr_train==3 & tr_test==3),t.test(auc[scrambled==FALSE],auc[scrambled==TRUE]))
#train tr 4, test tr 3 above chance
with(subset(trsweep_df, tr_train==4 & tr_test==3),t.test(auc[scrambled==FALSE],auc[scrambled==TRUE]))
#train tr 3, test tr 5 below chance
with(subset(trsweep_df, tr_train==3 & tr_test==5),t.test(auc[scrambled==FALSE],auc[scrambled==TRUE]))
#train tr 4, test tr 5 shows no diff from chance
with(subset(trsweep_df, tr_train==4 & tr_test==5),t.test(auc[scrambled==FALSE],auc[scrambled==TRUE]))
```

Let's visualize the result, using our friend ggplot.

```{r plot tr_sweep_fig}
tr_sweep_fig <- ggplot(trsweep_dfS, aes(x=as.numeric(tr_test), y=mean_auc,color=interaction(scrambled,factor(tr_train)),fill=factor(tr_train),alpha=.5))+  geom_ribbon(aes(ymin=mean_auc-sem_auc, ymax=mean_auc+sem_auc))+geom_line(linetype='dashed')+plotformat+fiftyline+ylim(.4,.7)+theme_bw()
tr_sweep_fig
```



Let's depict this as a visualization.

#Figure 8: ROIS
##EX>CM
```{r look at EX>CM in rois}
roi_dat_file = sprintf('%s/aucSummary__EXCM_masked.csv',dir)
roi_df = read.csv(roi_dat_file,header=T)
```

```{r make some plots}
roi_dfS<-ddply(roi_df,c("mask","tr"),summarise,N=length(auc),mean_auc=mean(auc),sd_auc = sd(auc), sem_auc=sd_auc/sqrt(N), min_auc = mean_auc-sem_auc, max_auc = mean_auc+sem_auc)

ggplot(roi_dfS,aes(x=tr,y=mean_auc))+geom_pointrange(position = position_dodge(.3), aes(color=mask, group=mask,ymin=min_auc,ymax=max_auc),size=1.15)+fiftyline+labs(title='EX>CM roi aucs')+theme_bw()+plotformat

```

##ROI TR sweep
There's a new excm sheet in town, so let's look at it
```{r load ex cm df}
excm_file = sprintf('%s/aucSummary__EXCM.csv',dir)
excm_df = read.csv(excm_file,header=T)
```

```{r roi labels}
roiNames = c("SEPT09_MVPA_MASK_resliced4mm","rblSplMask_mel101714","rmtlMask_hipPhgAmg_mel101714","rblAngMask_mel101714")
```


```{r fix tr weight variables}
trCodes = c("1;0;0;0;0;0","0;1;0;0;0;0","0;0;1;0;0;0","0;0;0;1;0;0","0;0;0;0;1;0","0;0;0;0;0;1")
ntrNames = length(trCodes)
for (i in 1:6){
  excm_df$trW[excm_df$trWeights==trCodes[i]]=i
  excm_df$trW_train[excm_df$trWeights_train==trCodes[i]]=i
  excm_df$trW_test[excm_df$trWeights_test==trCodes[i]]=i
}
excm_df$lateTrs = (excm_df$trWeights_train=="0;0;0.33;0.34;0.33;0")
excm_df$sameTr_trainTest = (excm_df$trWeights_train==excm_df$trWeights_test)

```

```{r summarize ex cm}
excm_df$train_test = 'EX>CM'
excm_dfS<-ddply(excm_df,.(which_traintest,trW,trW_train,trW_test,scramble,lateTrs,roiName,sameTr_trainTest),summarise,N=length(auc),mean_auc=mean(auc,na.rm=T),sd_auc = sd(auc,na.rm=T), sem_auc=sd_auc/sqrt(N),min_auc=mean_auc-sem_auc,max_auc=mean_auc+sem_auc)
```

##Train on tr 3, test on all trs
```{r tr sweep plot ex cm, fig.width=12, fig.height =6}
qplot(data=subset(excm_dfS,trW_train==3),x=trW_test,y=mean_auc,ymin=min_auc,ymax=max_auc,geom='ribbon',fill=roiName,color=roiName,alpha=.8,group=scramble)+geom_line(linetype='dashed')+facet_wrap(~roiName,ncol=3)+fiftyline
```

##Train and test on all trs
```{r train test same tr plot ex cm, fig.width=12, fig.height =6}
qplot(data=subset(excm_dfS,sameTr_trainTest==1),x=trW_test,y=mean_auc,ymin=min_auc,ymax=max_auc,geom='ribbon',fill=roiName,color=roiName,alpha=.8,group=scramble)+geom_line(linetype='dashed')+facet_wrap(~roiName,ncol=3)+fiftyline
```

##late trs
```{r late violins}
qplot(data=subset(excm_df,lateTrs==1),x=roiName,y=auc,geom='violin',fill=roiName,color=roiName,group=roiName,trim=F)+geom_point(color='black',stat='summary',fun.y='mean')+fiftyline
```




