---
title: "CM mvpa analysis"
output: 
  html_document:
    toc: true

---
This document will contain the figures we publish in our countermeasures manuscript.

#Load packages
First off, we'll need to **load the packages** we plan to use. This is not so different from setting the matlab path at the beginning of a script. 
```{r load_packages}
require(plyr) #plyr is used to summarize data along dimensions we care about
require(ggplot2) #ggplot! our favorite plotting tool
require(gridExtra) #gridExtra let's us arrangement figures into grids
require(reshape)
```

#Setup plotting variables
Then, we'll **setup some plotting environment variables** that we'll use to control how our plots look.

```{r set up plot variables}
#the color blind compatible palette we'll use for our colors
cbPalette <- c( "#56B4E9","#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7","#999999", "#E69F00")

#a dashed horizontal line to represent chance for binary classifiers
fiftyline=stat_abline(intercept=.5,slope=0,linetype="dashed",color='black',size=.75,alpha=.9)

#specify font size and face for axis labels and title
plotformat=theme(title= element_text(size=17),axis.title = element_text(size=17),axis.text.x=element_text(size=15),axis.text.y=element_text(size=15), legend.text=element_text(size=20),strip.text.x = element_text(size = 17))+theme_classic()
```

We'll have to be a little bit clever about getting our color palette into the plots, but the 50% chanceline and plotformats we can just do by adding them to our ggplots, i.e. `myplot + fiftyline`. so simple!

If I wasn't using this document as an R markdown tutorial, I would probably not show this code chunk in the html output. I could have hidden it by adding `echo=FALSE` to the code chunk header (note: code chunk headers are the thing in the Rmd that looks like :
```{r <chunk_title>, echo=TRUE, fig.width = 5, fig.height = 3}```

#Load the data
Now that we've got that setup, we'll **grab the data** that we plan to use a bunch from our 'results_sheets' directory.

```{r load_data}
dir = "~/cm/results_sheets" #all our results csvs live here 
#specify the name of each results sheet we'll use
behav_dat_file = sprintf("%s/cm_behav_to_r.csv",dir)
univ_dat_file = sprintf("%s/CM_betas_toR.csv",dir)
mvpa_dat_file = sprintf("%s/aucSummaryToR__exex_excm_cmcm_hitvcr.csv",dir)
#load each results sheet as it's own dataframe
behav_df = read.csv(behav_dat_file, header=T)
univ_df = read.csv(univ_dat_file, header=T)
mvpa_df = read.csv(mvpa_dat_file, header=T)
```

#Behavioral Findings
##Inspect Behavioral Data
The first thing we'll want to do is have a look at the structure of the behavioral data. We'll use `head` and `summary` to do this.

```{r summarize behavior}
head(behav_df) #head shows column headers and the first 6 rows of a data frame
summary(behav_df) #summary provides some information about the distribution of data in the data frame
```

Great. We can see that this data frame contains overall and task-specific d' and Pr for 16 EA subjects and 8 AA subjects

For now, we'll move onto the univariate data. It'll be happy to see us later.

##Inspect univariate data
```{r summarize univariate}
summary(univ_df)
```

Looks like we have a collection of parameter estimates ($\beta$s) for hits and crs in two tasks (ex and cm) from different contrasts and rois of different shapes (cluster vs sphere).  

##Create summary univariate data frame for plotting
A good (but not always necessary) first step to plotting, is to create a summary data frame, with the info you'd like. We'll do that for the mean and sem of the parameter estimates and we'll call the result `univ_dfS`.

```{r create univariate summary dataframe}
univ_dfS = ddply(univ_df,.(Contrast, shape, roi, task, acc),summarise,N=length(beta), mean_beta = mean(beta), sd_beta = sd(beta), sem_beta = sd_beta/sqrt(N), min_beta = mean_beta-sem_beta, max_beta = mean_beta+sem_beta)
summary(univ_dfS)
```

The summary looks great! So, now we can plot make some plots using these mean and sem values.

##Make univariate summary plot
Let's plot our mean $\beta$ for each task and subject accuracy (hit or cr) in facets for each contrast, roi, and sphere vs cluster

First, in order for the plot to display the factors in the order we want, we should reorder them in the data frame.

```{r reorder univ df factors}
univ_dfS$task = factor(univ_dfS$task, levels=c("ex","cm"))
univ_dfS$acc = factor(univ_dfS$acc, levels=c("hit","cr"))
```

Ok, now we can write a quick function to plot the data.


```{r plot univariate data}
plotUnivBetas <- function(pl_df){
#setup a plot h showing mean betas by task and memory
h<-ggplot(pl_df, aes(x=interaction(acc,task), y=mean_beta,ymin=min_beta,ymax=max_beta, fill = task))+#tells our plot what value to put on the x-axis and y-axis and to group values by task. If we tried to plot now, it would say "no layers in plot" and show nothing
   geom_bar(stat='identity',color='black')+
  geom_errorbar(position=position_dodge(1), width=0, size=1, color='black')+#here's the meat of the plot. this specifies that we want points with error bars, tells it what values to use for the error bars, how big their should be, and that they should be 'dodged' by grouping on the x-axis
  scale_fill_manual(values=cbPalette,name="Task",breaks=c("ex","cm"),labels=c("EX","CM"))+
  labs(x="Memory",y="Parameter estimate")+#here we specify what the labels should be
scale_x_discrete(breaks=c("hit.ex","cr.ex","hit.cm","cr.cm"),labels=c("Hit","CR","Hit","CR"))+
    plotformat + #this just tells our plot that it should have axis labels of a certain size, etc (see "Setup plotting variables" section)
theme(legend.text=element_text(size=14))
return(h)
}
```

Let's look at a first pass with all of the univariate data
```{r first pass univ plot, fig.width=10, fig.height=3}
plotUnivBetas(univ_dfS)+  theme(legend.position=c(.85,0.2))+ #let's we move the legend into a postion that's currently vacant 
facet_wrap(~roi+Contrast+shape,scales='free_y')#We'll 'facet' by the remaining factors, thereby making a separate plot for each combo of the factors. Note that we have to specify that y axis can be different in each facet. Now, we've got something we can actually think about plotting. 
```

##Fig 2. Task x Memory Interaction 
Hmmm... we're actually going to want some more information on ips clusters, so let's assemble that.
```{r load ips clusters}
lIps_file = sprintf('%s/lIpsBetas.csv',dir)
lIps_dat = read.csv(lIps_file,header=T)
```

```{r clean up ips cluster data frames}
#label roi info
lIps_dat$shape = 'cluster'
lIps_dat$roi = 'Left IPS'
#reshape into data frame
ips_betas = melt(lIps_dat)
#label subject numbers
ips_betas$subNo = c(1,3:10,12:26)
#label the task and memory accuracy in the data
ips_betas$task[grepl('Explicit',ips_betas$variable)]='ex'
ips_betas$task[grepl('CM',ips_betas$variable)]='cm'
ips_betas$acc[grepl('Hit',ips_betas$variable)]='hit'
ips_betas$acc[grepl('CR',ips_betas$variable)]='cr'
#reorder factors for plotting
ips_betas$acc = factor(ips_betas$acc,levels=c('hit','cr'))
ips_betas$task = factor(ips_betas$task,levels=c('ex','cm'))
```

```{r summarize and merge ips betas with univariate df}
#summarize the data, getting the means, etc of beta values and merge with other data frame
#first average across the race variable (not referenced explicitly here)
ips_betas_S = aggregate(value~acc+task+subNo+roi+shape,ips_betas,mean)
ips_betas_S$beta=ips_betas_S$value
#summarize by accuracy, task, roi, shape for use in plot
ips_betas_S=ddply(ips_betas_S,c("acc","task","roi","shape"),summarise,N=length(beta),mean_beta=mean(beta),sd_beta = sd(beta), sem_beta=sd_beta/sqrt(N), min_beta = mean_beta-sem_beta, max_beta = mean_beta+sem_beta)
#merge new data frame with existing data frame
univ_dfS_ms<-merge(univ_dfS,ips_betas_S,all=T)
#choose the subset of the data corresponding to the rois we actually want to put into the plot
univ_dfS_ms<-subset(univ_dfS_ms,roi %in% c("Left Ang", "Left Hipp", "Left IPS"))
univ_dfS_ms$roi = factor(univ_dfS_ms$roi, labels=c("Left AnG", "Left Hippocampus", "Left IPS"))
```

```{r plot betas in rois for ms,  fig.width=9, fig.height=2.75}
plotUnivBetas(subset(univ_dfS_ms, shape=='cluster'))+facet_wrap(~roi,scales='free_y')+theme(strip.background = element_rect(colour="white", fill="white"))

```


##Fig 3. L Ang parameter estimates correlates with CM d'
We also want to know something about how the angular effects correlate with CM d'. Let's have a look at that.
```{r correlation cm d prime and ang fx sphere}
#first let's grab that cluster
univ_df_ang_sphere = subset(univ_df, shape=='sphere' & roi=="Left Ang" & task=='cm')
#and look at it's structure
summary(univ_df_ang_sphere)
ang_sphere_cm_memsuccess = univ_df_ang_sphere$beta[univ_df_ang_sphere$acc=='hit']-univ_df_ang_sphere$beta[univ_df_ang_sphere$acc=='cr']
cor.test(ang_sphere_cm_memsuccess,behav_df$cm_d)

h<-qplot(behav_df$cm_d,ang_sphere_cm_memsuccess,geom='smooth',method='lm')+geom_point(size=3, fill='white',shape=21)+labs(x="Memory performance in CM task (d')",y="Retrieval success effects in CM task")+plotformat+geom_abline(intercept=0,slope=0,linetype='dashed')+geom_vline(x=0,linetype='dashed')

h+coord_equal(ratio=2.4/2.25,xlim=c(-.25,2.15),ylim=c(-1.75,.5))
  

```

note: This correlation is NOT significant at $p<.05$, when we use the *sphere* that produced the data above (for the bar graph). However, it is significant when we use the *cluster* and a one-tailed test.


```{r correlation cm d prime and ang fx cluster}
#first let's grab that cluster
univ_df_ang_clus = subset(univ_df, shape=='cluster' & roi=="Left Ang" & task=='cm')
#and look at it's structure
summary(univ_df_ang_clus)
ang_clus_cm_memsuccess = univ_df_ang_clus$beta[univ_df_ang_clus$acc=='hit']-univ_df_ang_clus$beta[univ_df_ang_clus$acc=='cr']
cor.test(ang_clus_cm_memsuccess,behav_df$cm_d)

qplot(behav_df$cm_d,ang_clus_cm_memsuccess,geom='smooth',method='lm')+geom_point(size=3.5, fill='white',shape=21)+labs(x="Memory performance in CM task (d')",y="Retrieval success effects in CM task")+plotformat+geom_abline(intercept=0,slope=0,linetype='dashed')+geom_vline(x=0,linetype='dashed')+coord_equal(xlim=c(-.27,2.1),ylim=c(-1.87,.5))


````


---------------
#MVPA Findings
##Inspect mvpa data frame
```{r summarize mvpa}
summary(mvpa_df)
```

Looks good. It'll be helpful to have a summary of this, so let's go ahead and make another dataframe (`mvpa_dfS`) that summarizes the information with mean, sem, and other info.

```{r make late trs df}
#reorder factors as appropriate
train_test_levels = c('EX,4fold','CM,4fold','EX>CM','CM>EX')
latetrs_mvpa_df = subset(mvpa_df,tr=='late' & train_test %in% train_test_levels)
latetrs_mvpa_df$train_test=factor(latetrs_mvpa_df$train_test,levels=train_test_levels)
#create summary df
mvpa_dfS<-ddply(mvpa_df,c("mask","conds","tr","name","train_test"),summarise,N=length(auc),mean_auc=mean(auc),sd_auc = sd(auc), sem_auc=sd_auc/sqrt(N), min_auc = mean_auc-sem_auc, max_auc = mean_auc+sem_auc)
```

The first thing we'll want to plot, is the ex>ex and ex>cm violins and tr by tr stuff that go into figure 4.

First thing I'll do is write some functions that make these plots easy to create.
####Plotting function for mvpa violins
```{r  mvpa comparison violins}
plotMvpaViolin <- function(pl_df){
  h<-ggplot(pl_df, aes(x=train_test, y=auc))+
    geom_violin(aes(fill=train_test),trim=F,alpha=.6)+
    geom_point(aes(color=sub),show_guide=F)+
    geom_line(aes(color=sub, group=sub),show_guide=F,linetype='dotted')+
    
    fiftyline+
    theme(axis.ticks=element_blank(),axis.text.x=element_blank())+
    plotformat+
    geom_point(stat='summary',fun.y='mean')
  return(h)
}
```

####Plotting function for mvpa at each tr
```{r  mvpa tr by tr plot}
plotMvpaTrRibbons <- function(pl_df){
  h<-ggplot(pl_df, aes(x=trSec,y=mean_auc,ymin=min_auc,ymax=max_auc, group=train_test, fill=train_test, color=train_test)) +
     geom_ribbon(alpha=.65) + 
    geom_line(linetype="longdash", size =1)+
    fiftyline+geom_vline(xintercept=0, linetype="dotted")+
    theme_bw() +
    plotformat+
    scale_x_discrete(breaks=seq(2,12,2))
  return(h)
}
```

####function to fix tr info in mvpa dfs
```{r fix tr}
fixTrInMvpaDf<-function(df){
trCodes = c("1;0;0;0;0;0","0;1;0;0;0;0","0;0;1;0;0;0","0;0;0;1;0;0","0;0;0;0;1;0","0;0;0;0;0;1")
ntrNames = length(trCodes)
for (i in 1:6){
  df$trW[df$trWeights==trCodes[i]]=i
  df$trW_train[df$trWeights_train==trCodes[i]]=i
  df$trW_test[df$trWeights_test==trCodes[i]]=i
}
df$lateTrs = (df$trWeights_train=="0;0;0.33;0.34;0.33;0")
df$trSec = as.numeric(df$trW_test)*2-1
return(df)
}
```

##Fig 4A. EX>EX & EX>CM Violins

```{r plot train_ex violins }
plotMvpaViolin(subset(latetrs_mvpa_df,train_test %in% c('EX,4fold','EX>CM')))+
  labs(y="Classifier Performance (AUC)", x="Testing Data (task)", title="Explicit Memory Classiier")+
  scale_fill_manual(values=cbPalette,name="Testing Data",breaks=c("EX,4fold","EX>CM"),labels=c("EX (cross-validated)","CM"))+
  scale_x_discrete(breaks=c("EX,4fold","EX>CM"),labels=c("EX","CM"))

```

##Fig 4B. EX>EX & EX>CM TR by TR
First, I want to create a variable `trSec` that corresponds to the number of second post stimulus onset (rather than the tr number), so that we can put that on the x axis

```{r get seconds for tr by tr}
mvpa_dfS$trSec = as.numeric(mvpa_dfS$tr)*2-1
mvpa_dfS$trSec[mvpa_dfS$tr=='late'] = NA
```

Now that I have that, plot away
```{r plot tr by tr training on ex}
plotMvpaTrRibbons(subset(mvpa_dfS, train_test %in% c("EX>CM","EX,4fold") & !is.na(trSec)))+
  scale_fill_manual(values=cbPalette,name="Testing Data",breaks=c("EX,4fold","EX>CM"),labels=c("EX (cross-validated)","CM"))+
  scale_color_manual(values=cbPalette,name="Testing Data",breaks=c("EX,4fold","EX>CM"),labels=c("EX (cross-validated)","CM"))+
  labs(x="Time Post Stimulus Onset (s)", y="Classifier Performance (AUC)")
```

##Fig 5A. Classifier Performance by Confidence 
To explore these effects, we're going to need to load new data that looks at trail by trial information, instead of binning across each classifier
###Load data
```{r load_this_mvpa_dat}
mvpa_extocm_tr3_file = sprintf("%s/xvals2_runsrepotred_conds_hitVcr_trTe1_1_1_1_2_2_2_2_trW0__0__1__0__0__0_roiSEPT09_MVPA_MASK_resliced4mm.csv",dir) 

mvpa_extocm_late_file = sprintf("%s/xvals2_runsrepotred_conds_hitVcr_trTe1_1_1_1_2_2_2_2_trWtr0___________0________0.33________0.34________0.33___________0_te0___________0________0.33________0.34________0.33___________0_roiSEPT09_MVPA_MASK_resliced4mm.csv",dir) 


mvpa_ex_late_file = sprintf("%s/xvals_runsrepotred_conds_hitVcr_trTe1_2_3_4_0_0_0_0_trW0___________0________0.33________0.34________0.33___________0_roiSEPT09_MVPA_MASK_resliced4mm.csv",dir) 

mvpa_extocm_tr3_df = read.csv(mvpa_extocm_tr3_file, header=T)
mvpa_extocm_late_df = read.csv(mvpa_extocm_late_file, header=T)
mvpa_ex_late_df = read.csv(mvpa_ex_late_file, header=T)
```

###Add labels to data and combine
```{r add labels and combine}

mvpa_extocm_tr3_df$name = 'extocm_tr3'
mvpa_extocm_late_df$name = 'extocm_late'
mvpa_ex_late_df$name = 'extoex_late'

confbyacc_df = rbind(mvpa_extocm_tr3_df,mvpa_extocm_late_df,mvpa_ex_late_df)
```

###Create percentile confidence bins of the data
```{r build confidence bins, cache = T}
confbyacc_sorted_df = confbyacc_df[with(confbyacc_df, order(name, subs, -abs(actsVec-.5))),]
acc = numeric(0)
subj_num = integer(0)
mvpa_name = character(0)
bin_name = character(0)
bin_num=numeric(0)
  
bins =seq(1,.05,-.05)

names = unique(confbyacc_sorted_df$name)
x=0
for (iname in 1:length(names)){
  this_name = names[iname]
  for (jsub in unique(confbyacc_sorted_df$subs)){
    ntrials = length(with(confbyacc_sorted_df, confbyacc_sorted_df[subs==jsub & name==this_name, "subs"]))
    for (acc_bin in seq(1,20)){
      x=x+1
      included_trial_inds = 1:ceiling(ntrials * bins[acc_bin])
      mvpa_name[x]=this_name
      subj_num[x]=jsub
      bin_name[x] = sprintf('top %s%%',bins[acc_bin]*100)
      bin_num[x]=acc_bin
      acc[x] = with(subset(confbyacc_sorted_df,name==this_name & subs==jsub),mean(correctsVec[included_trial_inds]))
    }
  }
}

mvpa_accbyconf_df = data.frame(sub = subj_num,name = mvpa_name, acc=acc, bin_name=bin_name, bin_num=bin_num)

mvpa_accbyconf_df$bin_name = factor(mvpa_accbyconf_df$bin_name,
                                      levels=(mvpa_accbyconf_df$bin_name[1:20]))

```


###Fit a model and make a plot of accuracy by percentile confidence
```{r plot accuracy by confidence percentile, fig.height=6, fig.width=6}

confacc_ag<-ddply(mvpa_accbyconf_df,c("bin_num","name"),summarise,N=length(acc),mean_acc=mean(acc),sd_acc = sd(acc), sem_acc=sd_acc/sqrt(N), min_acc = mean_acc-sem_acc, max_acc = mean_acc+sem_acc)

model<- lm(acc~bin_num*name,data=mvpa_accbyconf_df)
grid <- with(mvpa_accbyconf_df, expand.grid(
  name = levels(name),
  bin_num = bin_num
))
grid$acc<-stats::predict(model,newdata=grid)

confacc_plt<-ggplot(mvpa_accbyconf_df,aes(x=bin_num,y=acc,group=name,color=name))+plotformat+labs(x='Percentile confidence bin',y="Classifier accuracy",title="Classifier performance by confidence")+theme(axis.text.x  = element_text(angle=70, vjust=0.5))

labs = list(expression(paste("EX", symbol('\256'), "CM, late TRs")), expression(paste("EX" , symbol('\256'), "CM, 3rd TR")),"EX (cross-validated), late TRs")

confacc_plt=confacc_plt+geom_pointrange(data=confacc_ag,aes(x=bin_num,y=mean_acc,ymin=min_acc,ymax=max_acc,shape=name),size=1)+  
  geom_line(data=grid,size=.75) + 
  scale_x_continuous(labels=mvpa_accbyconf_df$bin_name[seq(1,20,2)],breaks=seq(1,20,2))+
  scale_color_manual(breaks=c("extocm_late","extocm_tr3","extoex_late"),labels=labs,name='',values=cbPalette[c(2,2,1)])+
  scale_shape_manual(breaks=c("extocm_late","extocm_tr3","extoex_late"),labels=labs,name='',values=c(16,17,16))

confacc_plt+theme(legend.position=c(.25, .87))

#confacc_ag

```


##Fig 5B. EX>CM TR3 Classifier Performance by CM d'
```{r cm d prime vs ex to cm tr 3}
excmtr3 = mvpa_df[mvpa_df$tr==3 & mvpa_df$train_test=="EX>CM",]
excmtr3$cm_d = behav_df$cm_d
excmtr3$ex_d = behav_df$ex_d
```

```{r ex d prime not correlated to cm tr 3 auc}
#what about with ex d'?
with(excmtr3,cor.test(auc,ex_d))
```

**EX d' is NOT significantly correlated with EX>CM AUC at tr 3 (4-6s post stimulus)**

```{r cm d prime is correlated to cm tr 3 auc}
#are these correlated with cm d'
with(excmtr3,cor.test(auc,cm_d))
```

**CM d' is significantly correlated with EX>CM AUC at tr 3 (4-6s post stimulus)** 

```{r plot correlation between auc and cm d}
#plot them
ggplot(excmtr3,aes(y=auc,x=cm_d))+geom_smooth(method="lm")+geom_point(size=3,fill='white',shape=21)+plotformat+labs(y="EX>CM Classifier Performance (AUC)",x="Memory performance in CM task (d')")+coord_fixed(ratio=2.37/.4,xlim=c(-.27,2.1),ylim=c(.25,.75))

```


##Fig 6. CM>CM and CM>EX Violins!

```{r plot train_cm violins, fig.width=5, fig.eight=6}
plotMvpaViolin(subset(latetrs_mvpa_df,train_test %in% c('CM,4fold','CM>EX')))+
  labs(y="Classification Performance (AUC)", x="Testing Data (task)", title="Decoding Performance")+
  scale_fill_manual(values=cbPalette[c(2,1)],name="",breaks=c("CM,4fold","CM>EX"),labels=c("CM (cross-validated)","EX"))+
  scale_x_discrete(breaks=c("CM,4fold","CM>EX"),labels=c("",""))+
  theme(legend.position=c(.67, .83),axis.ticks.x=element_blank())
```


##Fig ?. Tr Sweep!
First, load the data from our special TR sweep results sheet.
```{r load tr sweep df}
trsweeptrsweep_file = sprintf('%s/aucSummary__EXCMTrSweep.csv',dir)
trsweeptrsweep_df = read.csv(trsweeptrsweep_file,header=T)
trsweep_df=trsweeptrsweep_df
```

Let's depict this as a visualization.

#ROIS
##EX>CM
##ROI TR sweep: Train on tr 3, test on all trs

```{r load ex cm df}
trsweep_file = sprintf('%s/aucSummary__trsweep.csv',dir)
trsweep_df = read.csv(trsweep_file,header=T)
```

```{r play with factors}
trsweep_df$scramble = as.factor(trsweep_df$scramble)
trsweep_df$conds_traintest = with(trsweep_df,paste(condNames, which_traintest))
```

```
summary(trsweep_df)
```

```{r fix tr weight variables}
trsweep_df = fixTrInMvpaDf(trsweep_df)
```

```{r summarize ex cm}

trsweep_dfS<-ddply(trsweep_df,.(condNames,name,conds_traintest,which_traintest,trW,trW_train,trW_test,scramble,lateTrs,trSec,roiName),summarise,N=length(auc),mean_auc=mean(auc,na.rm=T),sd_auc = sd(auc,na.rm=T), sem_auc=sd_auc/sqrt(N),min_auc=mean_auc-sem_auc,max_auc=mean_auc+sem_auc)
```


```{r tr sweep plot ex cm, fig.width=15, fig.height =10,warning=F}


trsweep_dfS$train_test[trsweep_dfS$condNames=='exHit;exCr']="EX, 2fold"
trsweep_dfS$train_test[trsweep_dfS$condNames=='hit;cr']='EX>CM'
trsweep_dfS$roiLabel = factor(trsweep_dfS$roiName, labels = c("Left AnG", "Left MTL", "Left SPL","Right AnG","Right MTL", "Right SPL", "Whole brain"))

plotMvpaTrRibbons(subset(trsweep_dfS,trW_train==3 & scramble == 0))+facet_wrap(~roiLabel)+
  scale_fill_manual(values=cbPalette,name="Testing Data",breaks=c("EX, 2fold","EX>CM"),labels=c("EX (cross-validated)","CM"))+
  scale_color_manual(values=cbPalette,name="Testing Data",breaks=c("EX, 2fold","EX>CM"),labels=c("EX (cross-validated)","CM"))+
  labs(x="Time Post Stimulus Onset (s)", y="Classifier Performance (AUC)")
```

*NOTE: EX>EX here is 2-fold cross-validated (as opposed to 4-fold)*

```{r tr sweep histograms, fig.width=15, fig.height =10}

#qplot(data=subset(trsweep_df,trW_train==3  & condNames=='hit;cr'),x=auc,group=interaction(roiName,trW_test,scramble),fill=as.factor(scramble),geom='bar',position='dodge',alpha=.5)+facet_wrap(~roiName+trW_test,ncol=6,scales='free')+plotformat
```

**Perhaps we should be increasing our power by using each iteration as an observation, rather than averaging and then comparing 24 observations**

```{r tr sweep stats}
masks=levels(trsweep_df$roiName)
pvals=''
tvals=''
names=''
mean_auc=''
scram_mean_auc=''
k=0
for (j in 1:length(masks)){
  for (i in 1:6){
    k=k+1
    test = t.test(auc~scramble,data=subset(trsweep_df, trW_train==3  & condNames=='hit;cr' & trW_test==i & roiName==masks[j]),paired=T)
    pvals[k]= test$p.value
    mean_auc[k]= mean(with(trsweep_df, auc[scramble==0 & trW_train==3  & condNames=='hit;cr' & trW_test==i & roiName==masks[j]]))
        scram_mean_auc[k]= mean(with(trsweep_df, auc[scramble==1 & trW_train==3  & condNames=='hit;cr' & trW_test==i & roiName==masks[j]]))
    tvals[k]= test$statistic
    names[k]=sprintf('%s/%02d',masks[j],i)

  }
}
cbind(names,pvals,tvals, mean_auc, scram_mean_auc)

```



##ROI TR by TR: Train and test on all trs
```{r load trbytr df}
trbytr_file = sprintf('%s/aucSummary_trbytr.csv',dir)
trbytr_df = read.csv(trbytr_file,header=T)
```

```{r play with trbytr factors}
trbytr_df$scramble = as.factor(trbytr_df$scramble)
trbytr_df$conds_traintest = with(trbytr_df,paste(condNames, which_traintest))
```

```
summary(trbytr_df)
```

```{r fix tr by tr weight variables}
  
trbytr_df=fixTrInMvpaDf(trbytr_df)
```

```{r summarize trbytr}

trbytr_dfS<-ddply(trbytr_df,.(condNames,name,conds_traintest,which_traintest,trW,trW_train,trW_test,trSec,scramble,lateTrs,roiName),summarise,N=length(auc),mean_auc=mean(auc,na.rm=T),sd_auc = sd(auc,na.rm=T), sem_auc=sd_auc/sqrt(N),min_auc=mean_auc-sem_auc,max_auc=mean_auc+sem_auc)
```


```{r trbytr plot ex cm, fig.width=15, fig.height =10,warning=F}

trbytr_dfS$trSec[trbytr_dfS$tr=='late'] = NA
trbytr_dfS$train_test[trbytr_dfS$conds_traintest=='exHit;exCr 1;2;3;4;1;2;3;4']="EX, 4fold"
trbytr_dfS$train_test[trbytr_dfS$conds_traintest=='hit;cr 1;1;1;1;2;2;2;2']='EX>CM'
trbytr_dfS$roiLabel = factor(trbytr_dfS$roiName, labels = c("Left AnG", "Left MTL", "Left SPL","Right AnG","Right MTL", "Right SPL", "Whole brain"))

plotMvpaTrRibbons(subset(trbytr_dfS, scramble == 0))+facet_wrap(~roiLabel)+
  scale_fill_manual(values=cbPalette,name="Testing Data",breaks=c("EX, 4fold","EX>CM"),labels=c("EX (cross-validated)","CM"))+
  scale_color_manual(values=cbPalette,name="Testing Data",breaks=c("EX, 4fold","EX>CM"),labels=c("EX (cross-validated)","CM"))+
  labs(x="Time Post Stimulus Onset (s)", y="Classifier Performance (AUC)")

```

```{r trbytr histograms, fig.width=15, fig.height =10}

#qplot(data=subset(trbytr_df,  condNames=='hit;cr'),x=auc,group=interaction(roiName,trW_test,scramble),fill=as.factor(scramble),geom='bar',position='dodge',alpha=.5)+facet_wrap(~roiName+trW_test,ncol=6,scales='free')+plotformat
```

**Perhaps we should be increasing our power by using each iteration as an observation, rather than averaging and then comparing 24 observations**

```{r trbytr stats}
masks=levels(trbytr_df$roiName)
pvals=''
tvals=''
names=''
k=0
for (j in 1:(length(masks)-1)){
  for (i in 1:6){
    k=k+1
    test = t.test(auc~scramble,data=subset(trbytr_df, condNames=='hit;cr' & trW_test==i & roiName==masks[j]),paired=T)
    pvals[k]= test$p.value
    tvals[k]= test$statistic
    names[k]=sprintf('%s/%02d',masks[j],i)

  }
}
cbind(names,pvals,tvals)

masks=levels(trbytr_df$roiName)
pvals=''
tvals=''
names=''
k=0
for (j in 1:(length(masks)-1)){
  for (i in 1:6){
    k=k+1
    test = t.test(auc~scramble,data=subset(trbytr_df, condNames=='exHit;exCr' & trW_test==i & roiName==masks[j]),paired=T)
    pvals[k]= test$p.value
    tvals[k]= test$statistic
    names[k]=sprintf('%s/%02d',masks[j],i)

  }
}
cbind(names,pvals,tvals)


```

#Other useful stats
##How does EX>CM decoding compare to chance
```{r ex to cm}
excmscram = read.csv(sprintf('%s/aucSummary_wb_excm_late_scram.csv',dir),header=T)
t.test(with(mvpa_df,auc[train_test=='EX>CM' & tr=='late']), with(excmscram,auc[scramble==1]),paired=T)
```

##How does EX>EX decoding compare to chance
```{r ex to ex}
exexscram = read.csv(sprintf('%s/aucSummary_wb_late_exex_scram.csv',dir),header=T)
t.test(with(mvpa_df,auc[train_test=='EX,4fold' & tr=='late']), with(exexscram,auc[scramble==1]),paired=T)
```


##How does CM>EX decoding compare to chance
```{r cm to ex}
cmexscram = read.csv(sprintf('%s/aucSummary_cmtoex_late.csv',dir),header=T)
t.test(with(mvpa_df,auc[train_test=='CM>EX' & tr=='late']), with(cmexscram,auc[scramble==1]),paired=T)
```
##How does CM>CM decoding compare to chance

```{r cm to cm vs scram}
cmcmscram= read.csv(sprintf('%s/aucSummary_cmtocm_late_wb.csv',dir),header=T)
t.test(with(mvpa_df,auc[train_test=='CM,4fold' & tr=='late']), with(cmcmscram,auc[scramble==1]),paired=T)
```

##How do CM>CM and EX>EX decoding compare?
```{r cm to cm vs ex to ex decoding}
t.test(auc~train_test,data=subset(latetrs_mvpa_df, train_test %in% c('EX,4fold','CM,4fold') & tr=='late'),paired=T)
```

##How does EX>CM at TR3 compare to chance?
```{r tr 3 ex to cm v chance}
excmtr3S= read.csv(sprintf('%s/aucSummary_wb_tr3_excm_scram_unscram.csv',dir),header=T)
t.test(auc~scramble,data=excmtr3S,paired=T)
```

##What about other Tr by tr analyses?
```{r }
excmtrs_scram= read.csv(sprintf('%s/aucSummary_wb_trbytr_excm_scrambled.csv',dir),header=T)
exextrs_scram= read.csv(sprintf('%s/aucSummary_wb_trbytr_exex_scrambled.csv',dir),header=T)

exextrs_scram=fixTrInMvpaDf(exextrs_scram)
t.test(with(mvpa_df, auc[tr==1 & train_test=='EX,4fold']),with(exextrs_scram, auc[trW_test==1]),paired=T)
t.test(with(mvpa_df, auc[tr==2 & train_test=='EX,4fold']),with(exextrs_scram, auc[trW_test==2]),paired=T)
t.test(with(mvpa_df, auc[tr==3 & train_test=='EX,4fold']),with(exextrs_scram, auc[trW_test==3]),paired=T)
t.test(with(mvpa_df, auc[tr==4 & train_test=='EX,4fold']),with(exextrs_scram, auc[trW_test==4]),paired=T)
t.test(with(mvpa_df, auc[tr==5 & train_test=='EX,4fold']),with(exextrs_scram, auc[trW_test==5]),paired=T)
t.test(with(mvpa_df, auc[tr==6 & train_test=='EX,4fold']),with(exextrs_scram, auc[trW_test==6]),paired=T)

excmtrs_scram=fixTrInMvpaDf(excmtrs_scram)
t.test(with(mvpa_df, auc[tr==1 & train_test=='EX>CM']),with(excmtrs_scram, auc[trW_test==1]),paired=T)
t.test(with(mvpa_df, auc[tr==2 & train_test=='EX>CM']),with(excmtrs_scram, auc[trW_test==2]),paired=T)
t.test(with(mvpa_df, auc[tr==3 & train_test=='EX>CM']),with(excmtrs_scram, auc[trW_test==3]),paired=T)
t.test(with(mvpa_df, auc[tr==4 & train_test=='EX>CM']),with(excmtrs_scram, auc[trW_test==4]),paired=T)
t.test(with(mvpa_df, auc[tr==5 & train_test=='EX>CM']),with(excmtrs_scram, auc[trW_test==5]),paired=T)
t.test(with(mvpa_df, auc[tr==6 & train_test=='EX>CM']),with(excmtrs_scram, auc[trW_test==6]),paired=T)
```